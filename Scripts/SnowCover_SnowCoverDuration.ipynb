{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c391d60",
   "metadata": {},
   "source": [
    "## Script to identify the Snow Cover (SC) status on the ground and calculate the Snow Cover Duration (SCD)\n",
    "\n",
    "This script was used to clear all cloud- and no-data flagged pixels for each hydrological year and to interpolate these data/ cloud gaps to identify the Snow Cover status on the ground. Additionally, it was used to calculate the Snow Cover Duration for each pixels of the current hydrological year within the study region (Central Asia)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64307a71",
   "metadata": {},
   "source": [
    "#### Before running this script: \n",
    "\n",
    "1. Use the script Download_MODIS.ipynb to download the needed MODIS Snow Cover Terra and Aqua data\n",
    "2. Use the script ReplaceMissing_MODIS.ipynb to search for missing MODIS Terra files and replace them with the corresponding MODIS Aqua files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the needed modules\n",
    "import os\n",
    "import shutil\n",
    "import xarray\n",
    "import h5py\n",
    "import glob\n",
    "import sys\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define needed folders, files and variables\n",
    "\n",
    "# folders\n",
    "# MODIS Terra folder: e.g. MOD10A1_20-21\n",
    "MODIS_terra_file_folder = 'path/to/your/MODIS_Terra_folder/'\n",
    "MODIS_aqua_file_folder = 'path/to/your/MODIS_Aqua_folder/'\n",
    "# Snow cover folder: e.g. SC_20-21\n",
    "SC_output_folder = 'path/to/your/SC_output_folder/'\n",
    "SCD_output_folder = 'path/to/your/SCD_output_folder/'\n",
    "\n",
    "# files\n",
    "SRTM = 'path/to/h23v04_srtm_subset_corrected.tif'\n",
    "SCD_output_array = 'SCD_current_hydrological_year.npz'\n",
    "SCD_output_raster = 'SCD_current_hydrological_year.tif'\n",
    "\n",
    "# variables\n",
    "cloud_threshold = 10\n",
    "NDSI_threshold_not_so_certain_snow = 10\n",
    "NDSI_threshold_quite_certain_snow = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b40aa7",
   "metadata": {},
   "source": [
    "### Important Function:\n",
    "\n",
    "#### 3-Day Temporal Interpolation:\n",
    "Function to perform a 3-day temporal interpolation on the Terra files that were stacked to an array. The primary purpose is to fill in missing values within the array based on the values from the previous and and the next days.\n",
    "\n",
    "#### SRTM Snowline Interpolation:\n",
    "This function performs an interpolation on the array based on a Digital Elevation Model (DEM) and a cloud cover threshold. It iterates over each layer in the data stack and calculates the precentage of cloud pixels in the current scene. Then it checks whether this values is below the cloud threshold of 10%. If it is not, the scene is skiped. Otherwise, the function proceeds with the interpolation and idetifies three different types of pixels (free = pixel values between 32 and 64; snow = pixel values >= 64; fullsnow = pixels with values >= 128). After that, it calculates snowlines for different scenarios:\n",
    "\n",
    " - Snow Free Snowline: max. elevation with non-snow pixels\n",
    "    \n",
    " - Snow Covered Snowline: min elevation with fully snow-covered pixels (if there are no pixels of this type, it uses the maximum elevation from the DEM)\n",
    "    \n",
    "After that, it updates the data of the current scene and assigns different values for each of the scenarios:\n",
    " - 66: pixel is originally cloud-covered and its elevation is above the snow free snowline (interpreted as a transition from cloud to snow)\n",
    " - 34: pixel is originally cloud-covered and its elevation is below the snow covered snowline (interpreted as a transition from cloud to free of snow)\n",
    " - 130: pixel is in a state of transition and its elevation is above the snow fullcovered snowline\n",
    " \n",
    "Finally, it updates the stack for the current scene with the modified version.\n",
    "\n",
    "#### Seasonal Interpolation:\n",
    "The function initializes two arrays which are used to keep track of valid data and the number of days since the last cloud-free observation.Then it enters a loop, that iterates over each scene of the data stack. Inside the loop, it creates an output folder and constructs a string which represents the name of the output file. Then, it makes a copy of the input data stack and fills missing values by interpolation. Additionally, it tracks the number of days since the last cloud-free observation in an array (initially filled with zeros) by incrementing values by 1 where the data stack is not 0. Then it iterates over each scene and performs interpolation to handle missing values and set a seasonal bit under certain conditions. It keeps track of the number of days since the last cloud-free observation in a separate array. Lastly, it  performs a seasonal interpolation on the stack to estimate snow cover information for each pixel in each scene and stores the results as individual TIFF files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions:\n",
    "\n",
    "# read in a MODIS .hdf files\n",
    "def read_MODIS_snow(file):\n",
    "    hdf_ds = gdal.Open(file, gdal.GA_ReadOnly)\n",
    "    band_ds = gdal.Open(hdf_ds.GetSubDatasets()[0][0], gdal.GA_ReadOnly) # 'Snow_Cover_Daily_Tile' v5, 'NDSI_Snow_Cover' v6\n",
    "    data = band_ds.ReadAsArray()\n",
    "    temp = np.copy(data)\n",
    "    data = np.full(temp.shape, 0, dtype=np.uint8) # Missing Data (cloud, polar night etc.)\n",
    "    data = np.where(temp < NDSI_threshold_not_so_certain_snow, 32, data) # Snow Free (NDSI < 0.1)\n",
    "    data = np.where((temp >= NDSI_threshold_not_so_certain_snow) & (temp < NDSI_threshold_quite_certain_snow), 64, data) # Snow not so certain  (NDSI >= 0.1 & NDSI < 0.4)\n",
    "    data = np.where((temp >= NDSI_threshold_quite_certain_snow) & (temp <= 100), 128, data) # Snow (NDSI >= 0.4)\n",
    "    data = np.where(temp == 237, 16, data) # Inland Water\n",
    "    data = np.where(temp == 239, 8, data) # Ocean\n",
    "    snow_qa_ds = gdal.Open(hdf_ds.GetSubDatasets()[2][0], gdal.GA_ReadOnly) # \"NDSI_Snow_Cover_Algorithm_Flags_QA\"\n",
    "    snow_qa = snow_qa_ds.ReadAsArray()\n",
    "    snow_qa = snow_qa[:,:,np.newaxis]\n",
    "    snow_qa_bits = np.unpackbits(snow_qa, axis=-1, bitorder='little') # Bit 0: Inland water\n",
    "    data = np.where((data > 16) & (snow_qa_bits[:,:,0]==1), 16, data) #Pixels are re-assigned to water\n",
    "    return data\n",
    "\n",
    "# read in a geotiff file using GDAL\n",
    "def read_tiff(file):\n",
    "    ds = gdal.Open(file, gdal.GA_ReadOnly)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    arr = band.ReadAsArray()\n",
    "    return arr\n",
    "\n",
    "# write geotiffs using GDAL (commented out the compresion because compressed files can not be read in later)\n",
    "def write_tiff(outfile, data, proj_info, dtype=gdal.GDT_Byte):\n",
    "    x,y = data.shape\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(outfile,y,x,1,dtype)#options=['COMPRESS=DEFLATE']\n",
    "    dst.SetGeoTransform(proj_info[0])\n",
    "    dst.SetProjection(proj_info[1])\n",
    "    dst.GetRasterBand(1).WriteArray(data)\n",
    "    dst = None\n",
    "    return ''\n",
    "\n",
    "# write 26 bit geotiffs using GDAL (commented out the compresion because compressed files can not be read in later)\n",
    "def write_tiff(outfile, data, proj_info, dtype=gdal.GDT_UInt16):\n",
    "    x,y = data.shape\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(outfile,y,x,1,dtype) #options=['COMPRESS=DEFLATE']\n",
    "    dst.SetGeoTransform(proj_info[0])\n",
    "    dst.SetProjection(proj_info[1])\n",
    "    dst.GetRasterBand(1).WriteArray(data)\n",
    "    dst = None\n",
    "    return ''\n",
    "\n",
    "# 3-day temporal interpolation\n",
    "def interpolate_3day(GSP_data_stack, missing_value=0):\n",
    "    temporary_GSP_stack = np.copy(GSP_data_stack)\n",
    "    N = GSP_data_stack.shape[2]\n",
    "    for j in range(N-1):\n",
    "        if j>0:\n",
    "            actual_data = np.copy(temporary_GSP_stack[:,:,j]) # today's data\n",
    "            prior_data = np.copy(temporary_GSP_stack[:,:,j-1])\n",
    "            next_data = np.copy(temporary_GSP_stack[:,:,j+1])\n",
    "            actual_data = np.where(actual_data == missing_value, next_data, actual_data)\n",
    "            actual_data = np.where(actual_data == missing_value, prior_data, actual_data)\n",
    "            changed_values = np.where((temporary_GSP_stack[:,:,j] == missing_value) & (actual_data != missing_value))\n",
    "            actual_data[changed_values]+=1\n",
    "            GSP_data_stack[:,:,j] = actual_data[:,:]\n",
    "    temporary_GSP_stack = None\n",
    "    return GSP_data_stack\n",
    "\n",
    "# SRTM snowline interpolation\n",
    "def srtm_interpolation(GSP_data_stack, dem, cloud_threshold):\n",
    "    N = GSP_data_stack.shape[2]\n",
    "    for j in range(N):\n",
    "        all_cloud_pixels=np.count_nonzero(GSP_data_stack[:,:,j] == 0)\n",
    "        cloud_stats=all_cloud_pixels/GSP_data_stack[:,:,j].size * 100\n",
    "        if cloud_stats<=cloud_threshold:\n",
    "            #print(\"Entered if with {}\".format(cloud_stats))\n",
    "            print('Cloud cover below ' + str(cloud_threshold)+ ' in scene '+ str(j))\n",
    "            free = np.where((GSP_data_stack[:,:,j] >= 32) & (GSP_data_stack[:,:,j] < 64))\n",
    "            snow = np.where(GSP_data_stack[:,:,j] >= 64)\n",
    "            fullsnow = np.where(GSP_data_stack[:,:,j] >= 128)\n",
    "            step3_data_subset = np.copy(GSP_data_stack[:,:,j])\n",
    "            if len(free[0])!=0:\n",
    "                snow_free_snowline = np.nanmax(dem[free])\n",
    "            else:\n",
    "                snow_free_snowline = 0.0\n",
    "            if len(snow[0])!=0:\n",
    "                snow_covered_snowline = np.nanmin(dem[snow])\n",
    "                if len(fullsnow[0])!=0:\n",
    "                    snow_fullcovered_snowline = np.nanmax(dem[snow])\n",
    "                else:\n",
    "                    snow_fullcovered_snowline = np.nanmax(dem)\n",
    "            else:\n",
    "                snow_covered_snowline = np.nanmax(dem)\n",
    "                snow_fullcovered_snowline = np.nanmax(dem)\n",
    "            #find the pixels to recode:\n",
    "            step3_data_subset = np.where((step3_data_subset == 0) & (dem > snow_free_snowline), 66, step3_data_subset) # cloud to snow\n",
    "            step3_data_subset = np.where((step3_data_subset == 0) & (dem < snow_covered_snowline), 34, step3_data_subset) # cloud to free\n",
    "            step3_data_subset = np.where((step3_data_subset == 66) & (dem > snow_fullcovered_snowline), 130, step3_data_subset)\n",
    "            GSP_data_stack[:,:,j] = step3_data_subset[:,:] \n",
    "    return GSP_data_stack\n",
    "\n",
    "# seasonal interpolation\n",
    "def seasonal_interpolation(GSP_data_stack, proj_info):\n",
    "    N = GSP_data_stack.shape[2]\n",
    "    last_valid = np.full([2400,2400],1,dtype=np.uint8)\n",
    "    days_to_cloudfree = np.full([2400,2400],0,dtype=np.uint16)\n",
    "    for j in range(N):\n",
    "        print(j)\n",
    "        os.makedirs(SC_output_folder, exist_ok=True)\n",
    "        season_name = 'SEASON10A1.A'+str(j+1)+'.tif'\n",
    "        if j < 100:\n",
    "            season_name = 'SEASON10A1.A0'+str(j+1)+'.tif'\n",
    "        if j < 10:\n",
    "            season_name = 'SEASON10A1.A00'+str(j+1)+'.tif'\n",
    "        #accuracy_name = 'ACC10A1.A%04i%03i.%s.tif'%(timestamp.tm_year, timestamp.tm_yday, xdct['tile'])\n",
    "        #cloud_distance_name = 'XCC10A1.A%04i%03i.%s.tif'%(timestamp.tm_year, timestamp.tm_yday, xdct['tile'])\n",
    "        tmp_gsp = np.copy(GSP_data_stack[:,:,j])\n",
    "        tmp_gsp = np.where((tmp_gsp==0)&(last_valid!=0),last_valid,tmp_gsp)\n",
    "        seasonal_bit = np.unpackbits(tmp_gsp[:,:,np.newaxis], axis=-1, bitorder='little')[:,:,2] # check if seasonal bit is already set\n",
    "        days_to_cloudfree = np.where((GSP_data_stack[:,:,j]!=0),0,days_to_cloudfree+1)\n",
    "        last_valid = np.where((GSP_data_stack[:,:,j]!=0),GSP_data_stack[:,:,j],last_valid)\n",
    "        tmp_gsp = np.where((days_to_cloudfree!=0)&(tmp_gsp>=8)&(seasonal_bit==0),tmp_gsp+4,tmp_gsp)\n",
    "        #tmp_gsp = np.where((tmp_gsp != 0)&(land_mask == 0),0,tmp_gsp) # mask no data\n",
    "        GSP_data_stack[:,:,j] = tmp_gsp\n",
    "        write_tiff(os.path.join(SC_output_folder, season_name), tmp_gsp, proj_info)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab987739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two lists (MODIS Terra and Aqua) and fill them with the respective file names\n",
    "# for this analysis we only need the terra_files\n",
    "\n",
    "# create two empty lists\n",
    "terra_files, aqua_files = [], []\n",
    "\n",
    "for filename in os.listdir(MODIS_terra_file_folder)+os.listdir(MODIS_aqua_file_folder):\n",
    "            #add_log_entry(log_file,'File found %s'%filename)\n",
    "            version = filename.split('.')[3]\n",
    "            if version == '006' or version == '061':\n",
    "                if filename.startswith('MOD10A1.') & filename.endswith('hdf'):\n",
    "                    terra_file = os.path.join(MODIS_terra_file_folder, filename)\n",
    "                    #add_log_entry(log_file,'Terra File found %s'%terra_file)\n",
    "                    terra_files.append(terra_file)\n",
    "                if filename.startswith('MYD10A1.') & filename.endswith('hdf'):\n",
    "                    aqua_file = os.path.join(MODIS_aqua_file_folder, filename)\n",
    "                    #add_log_entry(log_file,'Aqua File found %s'%aqua_file)\n",
    "                    aqua_files.append(aqua_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23306635",
   "metadata": {},
   "outputs": [],
   "source": [
    "terra_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the files from the terra_files list and store the information in an array (GSP_data_stack)\n",
    "N = len(terra_files)\n",
    "GSP_data_stack = np.full([2400, 2400, N], 0, dtype = np.uint8)\n",
    "\n",
    "for i in range(len(terra_files)):\n",
    "    print(terra_files[i])\n",
    "    terra_data = read_MODIS_snow(terra_files[i])\n",
    "    GSP_data_stack[:,:,i] = terra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508eb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSP_data_stack[:,:,150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f238911",
   "metadata": {},
   "source": [
    "### Plot of the Cloud Cover Percentage\n",
    "Visualization of the cloud coverage for each day as well as the min, max, and mean of one examplary year to get a better understanding of the data gaps due to clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fecb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Plot the cloud cover percentage for each day as well as the min, max, and mean of one examplary year \n",
    "\n",
    "# get the cloud cover percentage for every scene of the year\n",
    "N = GSP_data_stack.shape[2]\n",
    "cloud_stats_list = []\n",
    "\n",
    "for j in range(N):\n",
    "    all_cloud_pixels = np.count_nonzero(GSP_data_stack[:,:,j] == 0)\n",
    "    cloud_stats = all_cloud_pixels / GSP_data_stack[:,:,j].size*100\n",
    "    cloud_stats_list.append(cloud_stats)\n",
    "\n",
    "# create x-axis values corresponding to the day of the hydrological year\n",
    "x_values = range(len(cloud_stats_list))\n",
    "\n",
    "# plot the list with the cloud cover statistics as a line plot\n",
    "plt.plot(x_values, cloud_stats_list, marker = 'o', markersize = 3, linestyle = '-')\n",
    "\n",
    "# calculate the min, max, and mean percentage\n",
    "mean_percentage = sum(cloud_stats_list) / len(cloud_stats_list)\n",
    "min_value = min(cloud_stats_list)\n",
    "max_value = max(cloud_stats_list)\n",
    "\n",
    "# plot the min, max, and mean percentage as a horizontal line\n",
    "plt.axhline(y = mean_percentage, color = 'r', linestyle = '--', label = f'Mean Percentage: {mean_percentage:.2f}')\n",
    "plt.axhline(y = min_value, color = 'g', linestyle = '--', label = f'Minimum Value: {min_value:.2f}')\n",
    "plt.axhline(y = max_value, color = 'b', linestyle = '--', label = f'Maximum Value: {max_value:.2f}')\n",
    "\n",
    "# Add a horizontal line at y = 0.5\n",
    "y_horizontal = 10\n",
    "plt.axhline(y_horizontal, color='yellow', linestyle='--', label='Horizontal Line at y=0.5')\n",
    "\n",
    "\n",
    "# add labels, title, and legend\n",
    "plt.xlabel('Day of the Year')\n",
    "plt.ylabel('Cloud Cover [%]')\n",
    "plt.title('Cloud Cover')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1.0, 0.8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-day temporal interpolation\n",
    "GSP_data_stack = interpolate_3day(GSP_data_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794af753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srtm snowline elevation interpolation\n",
    "dem = read_tiff(SRTM)\n",
    "GSP_data_stack = srtm_interpolation(GSP_data_stack, dem, cloud_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c12efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal interpolation\n",
    "\n",
    "# get the projection information to be able to write out the result\n",
    "hdf_ds = gdal.Open(terra_files[1])\n",
    "ds = gdal.Open(hdf_ds.GetSubDatasets()[0][0])\n",
    "proj_info = ds.GetGeoTransform(), ds.GetProjection()\n",
    "\n",
    "# full seasonal filter\n",
    "done = seasonal_interpolation(GSP_data_stack, proj_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_ds = gdal.Open(terra_files[1])\n",
    "ds = gdal.Open(hdf_ds.GetSubDatasets()[0][0])\n",
    "proj_info = ds.GetGeoTransform(), ds.GetProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack snow cover ouput rasters to an array\n",
    "\n",
    "# list of SC output files\n",
    "SC_output_files = []\n",
    "\n",
    "for filename in os.listdir(SC_output_folder):\n",
    "    if filename.endswith('tif'):\n",
    "        SC_output_file = os.path.join(SC_output_folder, filename)\n",
    "        SC_output_files.append(SC_output_file)\n",
    "\n",
    "# open the SC raster files and stack them in an array\n",
    "N = len(SC_output_files)\n",
    "raster_data_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    # open the .tif SC file\n",
    "    with rasterio.open(SC_output_files[i]) as src:\n",
    "        # read the raster data as  array\n",
    "        raster_data_list.append(src.read(1))\n",
    "        \n",
    "raster_data_array = np.stack(raster_data_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fb8e1",
   "metadata": {},
   "source": [
    "### Calculation of the SCD\n",
    "A binary snow/ no snow mask is created, where all pixels that are less than 128 (no snow) are set to 0. Similarly, all pixel values greater than or equal 128 are set to 1 (snow). Then, the SCD is calculated for each pixel by summing up the binary values (0 or 1) for every scene of the hydrological year. The result is an array, where each element represets the SCD for the corresponding pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the SCD\n",
    "\n",
    "# copy the array (to keep the unchanged original)\n",
    "rda = np.copy(raster_data_array)\n",
    "\n",
    "# binary snow/ no snow mask\n",
    "# set all snow pixels (pixels > 128) to 1 and all no snow pixels (pixels < 128) to 0\n",
    "rda[rda < 128] = 0\n",
    "rda[rda >= 128] = 1\n",
    "\n",
    "# count the number of days with snow cover (1) per pixel\n",
    "rda_sum = np.sum(rda, axis = 0)\n",
    "\n",
    "# plot showing the snow cover duration for the hydrological year\n",
    "plt.imshow(rda_sum)\n",
    "plt.title('Snow Cover Duration one Hydrological Year')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the array containing the SCD\n",
    "np.save(os.path.join(SCD_output_folder, SCD_output_array), rda_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43bf493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the SCD array as .tif file\n",
    "write_tiff(os.path.join(SCD_output_folder, SCD_output_raster), rda_sum, proj_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb699f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rda_sum.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
